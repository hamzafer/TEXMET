#!/usr/bin/env python
"""
Met Textiles Ã— FiftyOne â€“ end-to-end pipeline
"""

import os, json, fiftyone as fo, fiftyone.brain as fob
import glob
import fiftyone as fo

print("ğŸ§¹ Cleaning up existing dataset...")
# fo.delete_dataset("met_textiles_27k")      # wipes the empty set

# ---------------------------------------------------------------------- #
# Paths â€“ adjust if you've moved things
# ---------------------------------------------------------------------- #
JSON_PATH  = (
    "../FINAL_CORRECTED_MET_TEXTILES_DATASET/objects_with_images_only/"
    "ALL_TEXTILES_AND_TAPESTRIES_WITH_IMAGES_20250705_230315.json"
)
IMAGES_DIR = "MET_TEXTILES_BULLETPROOF_DATASET/images"
DATASET_NAME = "met_textiles_27k"

print(f"ğŸ“‚ JSON Path: {JSON_PATH}")
print(f"ğŸ–¼ï¸  Images Directory: {IMAGES_DIR}")
print(f"ğŸ·ï¸  Dataset Name: {DATASET_NAME}")
print()

# ---------------------------------------------------------------------- #
# Helper â€“ map a JSON object â†’ local image path
# ---------------------------------------------------------------------- #
def resolve_image_path(obj):
    """
    Return a matching local image filepath for this Met object, or None.

    Look for:
      1.  <IMAGES_DIR>/<objectID>.<jpg|png>
      2.  <IMAGES_DIR>/<objectID>_*_primary.<jpg|png>
      3.  A file whose basename matches the remote primary image URL
      4.  The web-large fallback
    """
    oid = obj["objectID"]

    # 1. Straight ID
    basics = [
        os.path.join(IMAGES_DIR, f"{oid}.jpg"),
        os.path.join(IMAGES_DIR, f"{oid}.png"),
    ]

    # 2. Your "*_primary" naming pattern
    primary_glob = glob.glob(os.path.join(IMAGES_DIR, f"{oid}_*_primary.*"))
    basics.extend(primary_glob)

    # 3 & 4. Basenames from remote URLs (handles any residual file names)
    url_names = [
        os.path.basename(obj.get("primaryImage", "")),
        os.path.basename(obj.get("primaryImageSmall", "")),
    ]
    basics.extend(os.path.join(IMAGES_DIR, n) for n in url_names if n)

    # return the first path that exists
    for path in basics:
        if path and os.path.exists(path):
            return path

    return None

# ---------------------------------------------------------------------- #
# (Re)create the dataset
# ---------------------------------------------------------------------- #
print("ğŸ” Checking if dataset exists...")
if fo.dataset_exists(DATASET_NAME):
    print(f"âœ… Loading existing dataset: {DATASET_NAME}")
    ds = fo.load_dataset(DATASET_NAME)
else:
    print(f"ğŸš€ Creating new dataset: {DATASET_NAME}")
    print("ğŸ“– Loading JSON metadata...")
    with open(JSON_PATH, encoding="utf-8") as f:
        objects = json.load(f)
    
    print(f"ğŸ“Š Found {len(objects)} objects in JSON")
    print("ğŸ”— Resolving image paths...")
    
    samples = []
    missing_images = 0
    for i, obj in enumerate(objects):
        if i % 1000 == 0 and i > 0:
            print(f"   Processed {i}/{len(objects)} objects...")
        
        fp = resolve_image_path(obj)
        if fp is None:
            missing_images += 1
            continue  # skip if image missing

        samples.append(
            fo.Sample(
                filepath=fp,
                object_id=obj["objectID"],
                department=obj.get("department", ""),
                classification=obj.get("classification", ""),
                title=obj.get("title", ""),
                met_raw=obj,  # keep full metadata for convenience
            )
        )

    print(f"âœ… Created {len(samples)} samples")
    print(f"âš ï¸  Skipped {missing_images} objects with missing images")
    print("ğŸ’¾ Adding samples to dataset...")
    
    ds = fo.Dataset(DATASET_NAME, overwrite=True)
    ds.add_samples(samples)
    ds.persistent = True  # dataset survives Python restarts
    print("âœ… Dataset created and saved!")

print(f"\nğŸ“ˆ Dataset Overview:")
print(ds)  # sanity-check (should show 27 k samples)
print()

# ---------------------------------------------------------------------- #
# Compute CLIP embeddings once (GPU-accelerated)
# ---------------------------------------------------------------------- #
EMB_FIELD = "clip_emb"
print(f"ğŸ§  Checking for CLIP embeddings in field '{EMB_FIELD}'...")
if EMB_FIELD not in ds.get_field_schema():
    print("âš¡ Computing CLIP embeddings â€“ grab a coffee â˜•")
    print("   Using model: clip-vit-base32-torch")
    print("   Batch size: 64, Workers: 8")
    ds.compute_embeddings(                      
        model="clip-vit-base32-torch",          # choose another CLIP variant if desired
        embeddings_field=EMB_FIELD,
        batch_size=64,                          # tune for your GPU
        num_workers=8,
    )
    ds.save()
    print("âœ… CLIP embeddings computed and saved!")
else:
    print("âœ… CLIP embeddings already exist!")
print()

# ---------------------------------------------------------------------- #
# FiftyOne Brain goodies
# ---------------------------------------------------------------------- #
print("ğŸ§  Computing FiftyOne Brain features...")
print("   ğŸ¯ Computing uniqueness...")
fob.compute_uniqueness(ds, embeddings=EMB_FIELD)                 
print("   ğŸ“Š Computing representativeness...")
fob.compute_representativeness(ds, embeddings=EMB_FIELD)         

print("   ğŸ—ºï¸  Computing 3D UMAP visualization...")
fob.compute_visualization(                                       # 3-D UMAP for App
    ds,
    embeddings=EMB_FIELD,
    brain_key="clip_umap",
    method="umap",
    dim=3,
)                                                               

print("   ğŸ” Setting up similarity search (LanceDB)...")
fob.compute_similarity(                                          # fast NN search
    ds,
    embeddings=EMB_FIELD,
    brain_key="clip_sim",
    backend="lancedb",
)                                                               

print("   ğŸ” Finding near-duplicates...")
dup_results = fob.compute_near_duplicates(
    ds, embeddings=EMB_FIELD, threshold=0.18
)
print(f"   ğŸ“‹ Near-duplicate sets found: {len(dup_results.duplicate_ids)}")
print("âœ… All Brain features computed!")
print()

# ---------------------------------------------------------------------- #
# Launch interactive UI
# ---------------------------------------------------------------------- #
print("ğŸš€ Launching FiftyOne App...")
print("   Port: 5151")
print("   Opening browser tab...")
session = fo.launch_app(ds, port=5151)
session.open_tab()
session.wait()
print("ğŸ‰ FiftyOne App is ready! Enjoy exploring!")
